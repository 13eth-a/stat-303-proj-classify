{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5dbbea0e-3a99-459e-abd6-0959e6946869",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prediction Problem\"\n",
    "subtitle: \"STAT 303-3 Spring 25\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    code-fold: show\n",
    "    embed-resources: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec7523b-6099-4001-a997-60005980e73a",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "\n",
    "- Put the parts of your code under the corresponding sections. (0.25/2 points will be taken off for not doing this.)\n",
    "- Do not include any redundant/irrelevant code, text or comments. (0.5/2 points will be taken off for not doing this.)\n",
    "- **Your code must run without any errors or runtime issues.** (Failure to meet this condition will result in a 0.)\n",
    "- **Your code must return your Public Leaderboard score.** (Failure to meet this condition will result in a 0.)\n",
    "- **Submit both your ipynb and your html file for grading purposes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03031cca-1a24-4e66-926e-2b32f85f3cc7",
   "metadata": {},
   "source": [
    "## 1) Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d65f439-927b-4b40-9008-a715356fbe58",
   "metadata": {},
   "source": [
    "Put all the Python libraries and tools you imported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eb866b1-8f62-4ca4-a39e-5774486da357",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1877d116-1e8d-426e-84ba-10c47e28a1ac",
   "metadata": {},
   "source": [
    "## 2) Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177363af-51a7-4b16-b6d2-33ba5796bd20",
   "metadata": {},
   "source": [
    "- This section is required to include the code that reads, cleans and preprocesses the datasets.\n",
    "- Note that both the training and test datasets should undergo the same sequence of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddcc4a5b-777a-4b75-8fd7-b0594591ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "y = train['host_is_superhost']\n",
    "X = train.drop(columns=['host_is_superhost', 'id', 'description', 'host_about', 'first_review', 'last_review',\n",
    "                        'host_verifications', 'host_location', 'host_neighbourhood', 'neighbourhood_cleansed',\n",
    "                        'host_since', 'amenities', 'bathrooms_text'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "592d9d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "cat_cols = X_train.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "X_train[cat_cols] = X_train[cat_cols].astype(str)\n",
    "X_val[cat_cols] = X_val[cat_cols].astype(str)\n",
    "num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1078e4fa-9a22-44ca-b1e3-944f25dac70a",
   "metadata": {},
   "source": [
    "## 3) Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa5c8b4-9aab-4022-8561-5f8bf964cab3",
   "metadata": {},
   "source": [
    "- This section is required to train the **already tuned** model and obtain the test predictions (or prediction probabilities) with it.\n",
    "- As written in the instructions, your code must not have any runtime issues, so **do NOT include your grid search here!** You will still need to tune your model to pass the thresholds. However, you need to keep that as your personal work and should NOT include the grid search here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80ccfd51-090e-4685-a4fc-d26c8fbe12d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_transformer = Pipeline([('imputer', SimpleImputer(strategy='median'))])\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, num_cols),\n",
    "    ('cat', categorical_transformer, cat_cols)\n",
    "])\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(use_label_encoder=False, \n",
    "                                 subsample=0.8, \n",
    "                                 n_estimators=700,\n",
    "                                 min_child_weight=1,\n",
    "                                 max_depth=6,\n",
    "                                 learning_rate=0.07,\n",
    "                                 colsample_bytree=0.6,\n",
    "                                 eval_metric='auc', \n",
    "                                 random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc2d1c1-edd2-428c-9944-2bafc8f9291b",
   "metadata": {},
   "source": [
    "## 4) Exporting the Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e92cdc-e3e0-423a-a248-cf3b1cf99f68",
   "metadata": {},
   "source": [
    "Include the code that (1) puts the predictions in the format that Kaggle understands and (2) exports it as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1f881e2-bccf-49e3-aa6c-ff4381883031",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_full = pd.concat([X_train, X_val])\n",
    "y_full = pd.concat([y_train, y_val])\n",
    "model.fit(X_full, y_full)\n",
    "\n",
    "X_test = test.drop(columns=['id', 'description', 'host_about', 'first_review', 'last_review',\n",
    "                            'host_verifications', 'host_location', 'host_neighbourhood',\n",
    "                            'neighbourhood_cleansed', 'host_since', 'amenities', 'bathrooms_text'], errors='ignore')\n",
    "X_test[cat_cols] = X_test[cat_cols].astype(str)\n",
    "X_test = X_test.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "y_test_pred = model.predict_proba(X_test)[:, 1]\n",
    "submission = pd.DataFrame({'id': test['id'], 'predicted': y_test_pred})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asiignment0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
